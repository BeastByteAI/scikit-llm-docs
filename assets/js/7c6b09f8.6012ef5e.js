"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[686],{9103:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>d,toc:()=>o});var i=s(5893),n=s(1151);const l={sidebar_position:4},r="Tunable Text Classification",d={id:"classification/tunable-text-classification",title:"Tunable Text Classification",description:"Tunable estimators allow to fine-tune the underlying LLM for a classification task. Usually, tuning is performed directly in the cloud (e.g. OpenAI, Vertex), therefore it is not required to have a GPU on your local machine. However, be aware that tuning can be costly and time-consuming. We recommend to first try the in-context learning estimators, and only if they do not provide satisfactory results, to try the tunable estimators.",source:"@site/docs/classification/tunable-text-classification.md",sourceDirName:"classification",slug:"/classification/tunable-text-classification",permalink:"/scikit-llm-docs/docs/classification/tunable-text-classification",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Dynamic Few-Shot Text Classification",permalink:"/scikit-llm-docs/docs/classification/dynamic-few-shot-text-classification"},next:{title:"Text-to-text Modelling",permalink:"/scikit-llm-docs/docs/category/text-to-text-modelling"}},c={},o=[{value:"API Reference",id:"api-reference",level:2},{value:"GPTClassifier",id:"gptclassifier",level:3},{value:"MultiLabelGPTClassifier",id:"multilabelgptclassifier",level:3},{value:"VertexClassifier",id:"vertexclassifier",level:3}];function a(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,n.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"tunable-text-classification",children:"Tunable Text Classification"}),"\n",(0,i.jsx)(t.p,{children:"Tunable estimators allow to fine-tune the underlying LLM for a classification task. Usually, tuning is performed directly in the cloud (e.g. OpenAI, Vertex), therefore it is not required to have a GPU on your local machine. However, be aware that tuning can be costly and time-consuming. We recommend to first try the in-context learning estimators, and only if they do not provide satisfactory results, to try the tunable estimators."}),"\n",(0,i.jsx)(t.p,{children:"Example using GPT-3.5-Turbo-0613:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from skllm.models.gpt.classification.tunable import GPTClassifier\n\nX, y = get_classification_dataset()\nclf = GPTClassifier(n_epochs=1)\nclf.fit(X,y)\nclf.predict(X)\n"})}),"\n",(0,i.jsx)(t.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,i.jsx)(t.p,{children:"The following API reference only lists the parameters needed for the initialization of the estimator. The remaining methods follow the syntax of a scikit-learn classifier."}),"\n",(0,i.jsx)(t.h3,{id:"gptclassifier",children:"GPTClassifier"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from skllm.models.gpt.classification.tunable import GPTClassifier\n"})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Parameter"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Type"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Description"})})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"base_model"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"str"})}),(0,i.jsx)(t.td,{children:'Base model to use, by default "gpt-3.5-turbo-0613".'})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"default_label"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"str"})}),(0,i.jsx)(t.td,{children:'Default label for failed prediction; if "Random" -> selects randomly based on class frequencies, by default "Random".'})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"key"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:"Estimator-specific API key; if None, retrieved from the global config, by default None."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"org"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:"Estimator-specific ORG key; if None, retrieved from the global config, by default None."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"n_epochs"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[int]"})}),(0,i.jsx)(t.td,{children:"Number of epochs; if None, determined automatically; by default None."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"custom_suffix"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:'Custom suffix of the tuned model, used for naming purposes only, by default "skllm".'})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"prompt_template"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:"Custom prompt template to use, by default None."})]})]})]}),"\n",(0,i.jsx)(t.h3,{id:"multilabelgptclassifier",children:"MultiLabelGPTClassifier"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from skllm.models.gpt.classification.tunable import MultiLabelGPTClassifier\n"})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Parameter"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Type"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Description"})})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"base_model"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"str"})}),(0,i.jsx)(t.td,{children:'Base model to use, by default "gpt-3.5-turbo-0613".'})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"default_label"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"str"})}),(0,i.jsx)(t.td,{children:'Default label for failed prediction; if "Random" -> selects randomly based on class frequencies, by default "Random".'})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"key"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:"Estimator-specific API key; if None, retrieved from the global config, by default None."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"org"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:"Estimator-specific ORG key; if None, retrieved from the global config, by default None."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"n_epochs"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[int]"})}),(0,i.jsx)(t.td,{children:"Number of epochs; if None, determined automatically; by default None."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"custom_suffix"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:'Custom suffix of the tuned model, used for naming purposes only, by default "skllm".'})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"prompt_template"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[str]"})}),(0,i.jsx)(t.td,{children:"Custom prompt template to use, by default None."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"max_labels"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Optional[int]"})}),(0,i.jsx)(t.td,{children:"Maximum labels per sample, by default 5."})]})]})]}),"\n",(0,i.jsx)(t.h3,{id:"vertexclassifier",children:"VertexClassifier"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from skllm.models.vertex.classification.tunable import VertexClassifier\n"})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Parameter"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Type"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Description"})})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"base_model"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"str"})}),(0,i.jsx)(t.td,{children:'Base model to use, by default "text-bison@002".'})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"n_update_steps"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"int"})}),(0,i.jsx)(t.td,{children:"Number of epochs, by default 1."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"default_label"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"str"})}),(0,i.jsx)(t.td,{children:'Default label for failed prediction; if "Random" -> selects randomly based on class frequencies, by default "Random".'})]})]})]})]})}function h(e={}){const{wrapper:t}={...(0,n.a)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}},1151:(e,t,s)=>{s.d(t,{Z:()=>d,a:()=>r});var i=s(7294);const n={},l=i.createContext(n);function r(e){const t=i.useContext(l);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),i.createElement(l.Provider,{value:t},e.children)}}}]);