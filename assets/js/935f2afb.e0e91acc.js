"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:t=>{t.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Quick Start","href":"/scikit-llm-docs/docs/intro","docId":"intro","unlisted":false},{"type":"link","label":"Backend Families","href":"/scikit-llm-docs/docs/backend-families","docId":"backend-families","unlisted":false},{"type":"category","label":"Text Classification","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Zero-Shot Text Classification","href":"/scikit-llm-docs/docs/classification/zero-shot-classification","docId":"classification/zero-shot-classification","unlisted":false},{"type":"link","label":"Few-Shot Text Classification","href":"/scikit-llm-docs/docs/classification/few-show-text-classification","docId":"classification/few-show-text-classification","unlisted":false},{"type":"link","label":"Dynamic Few-Shot Text Classification","href":"/scikit-llm-docs/docs/classification/dynamic-few-shot-text-classification","docId":"classification/dynamic-few-shot-text-classification","unlisted":false},{"type":"link","label":"Tunable Text Classification","href":"/scikit-llm-docs/docs/classification/tunable-text-classification","docId":"classification/tunable-text-classification","unlisted":false}],"href":"/scikit-llm-docs/docs/category/text-classification"},{"type":"category","label":"Text-to-text Modelling","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Text Summarization","href":"/scikit-llm-docs/docs/text-to-text/text-summarization","docId":"text-to-text/text-summarization","unlisted":false},{"type":"link","label":"Text Translation","href":"/scikit-llm-docs/docs/text-to-text/text-translation","docId":"text-to-text/text-translation","unlisted":false},{"type":"link","label":"Tunable Text-to-text","href":"/scikit-llm-docs/docs/text-to-text/tunable","docId":"text-to-text/tunable","unlisted":false}],"href":"/scikit-llm-docs/docs/category/text-to-text-modelling"},{"type":"link","label":"Text Vectorization","href":"/scikit-llm-docs/docs/text-vectorization","docId":"text-vectorization","unlisted":false}]},"docs":{"backend-families":{"id":"backend-families","title":"Backend Families","description":"On a high level, Scikit-LLM estimators are divided based on the language model backend family they use. The backend family is defined by the API format and does not necessarily correspond to the language model architecture. For example, all backends that follow the OpenAI API format are groupped into gpt family regardless the actual language model architecture or provider. Eeach backend family has its own set of estimators which are located in the skllm.models. sub-module.","sidebar":"tutorialSidebar"},"classification/dynamic-few-shot-text-classification":{"id":"classification/dynamic-few-shot-text-classification","title":"Dynamic Few-Shot Text Classification","description":"Dynamic Few-Shot Classification is an extension of Few-Shot Text Classification that is more suitable for larger datasets. Instead of using a fixed set of examples for each class, it constructs a dynamic subset for each sample on the fly. This allows to efficiently utilize the limited contex window of the model and save the number of consumed tokens.","sidebar":"tutorialSidebar"},"classification/few-show-text-classification":{"id":"classification/few-show-text-classification","title":"Few-Shot Text Classification","description":"Few-shot text classification is a task of classifying a text into one of the pre-defined classes based on a few examples of each class. For example, given a few examples of the class positive, negative, and neutral, the model should be able to classify a new text into one of these classes.","sidebar":"tutorialSidebar"},"classification/tunable-text-classification":{"id":"classification/tunable-text-classification","title":"Tunable Text Classification","description":"Tunable estimators allow to fine-tune the underlying LLM for a classification task. Usually, tuning is performed directly in the cloud (e.g. OpenAI, Vertex), therefore it is not required to have a GPU on your local machine. However, be aware that tuning can be costly and time-consuming. We recommend to first try the in-context learning estimators, and only if they do not provide satisfactory results, to try the tunable estimators.","sidebar":"tutorialSidebar"},"classification/zero-shot-classification":{"id":"classification/zero-shot-classification","title":"Zero-Shot Text Classification","description":"One of the powerful features of LLMs is the ability to perform text classification without being re-trained. For that, the only requirement is that the labels must be descriptive.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Quick Start","description":"Scikit-LLM allows you to seamlessly integrate powerful language models into scikit-learn for enhanced text analysis tasks. Let\'s see how it is possible to use Scikit-LLM to perform zero-shot text classification with GPT-4.","sidebar":"tutorialSidebar"},"text-to-text/text-summarization":{"id":"text-to-text/text-summarization","title":"Text Summarization","description":"LLMs excel at performing summarization tasks. Scikit-LLM provides a summarizer that can be used both as stand-alone estimator, or as a preprocessor (in this case we can make an analogy with a dimensionality reduction preprocessor).","sidebar":"tutorialSidebar"},"text-to-text/text-translation":{"id":"text-to-text/text-translation","title":"Text Translation","description":"LLMs have proven their proficiency in translation tasks. To leverage this capability, Scikit-LLM provides the Translator module, designed for translating any given text into a specified target language.","sidebar":"tutorialSidebar"},"text-to-text/tunable":{"id":"text-to-text/tunable","title":"Tunable Text-to-text","description":"Tunable text-to-text estimators are estimators that can be tuned to perform a variety of tasks, including but not limited to text summarization, question answering, and text translation. These estimators use the provided data as-is, without any additional preprocessing, or constructing prompts. While this approach allows for more flexibility, it is the user\'s responsibility to ensure that the data is formatted correctly.","sidebar":"tutorialSidebar"},"text-vectorization":{"id":"text-vectorization","title":"Text Vectorization","description":"LLMs can be used solely for data preprocessing by embedding a chunk of text of arbitrary length to a fixed-dimensional vector, that can be further used with virtually any model (e.g. classification, regression, clustering, etc.).","sidebar":"tutorialSidebar"}}}')}}]);