"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[474],{6935:(e,s,i)=>{i.r(s),i.d(s,{assets:()=>r,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var t=i(5893),n=i(1151);const o={sidebar_position:3},a="Dynamic Few-Shot Text Classification",l={id:"classification/dynamic-few-shot-text-classification",title:"Dynamic Few-Shot Text Classification",description:"Dynamic Few-Shot Classification is an extension of Few-Shot Text Classification that is more suitable for larger datasets. Instead of using a fixed set of examples for each class, it constructs a dynamic subset for each sample on the fly. This allows to efficiently utilize the limited contex window of the model and save the number of consumed tokens.",source:"@site/docs/classification/dynamic-few-shot-text-classification.md",sourceDirName:"classification",slug:"/classification/dynamic-few-shot-text-classification",permalink:"/scikit-llm-docs/docs/classification/dynamic-few-shot-text-classification",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Few-Shot Text Classification",permalink:"/scikit-llm-docs/docs/classification/few-show-text-classification"},next:{title:"Tunable Text Classification",permalink:"/scikit-llm-docs/docs/classification/tunable-text-classification"}},r={},c=[{value:"API Reference",id:"api-reference",level:2},{value:"DynamicFewShotGPTClassifier",id:"dynamicfewshotgptclassifier",level:3}];function d(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,n.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.h1,{id:"dynamic-few-shot-text-classification",children:"Dynamic Few-Shot Text Classification"}),"\n",(0,t.jsxs)(s.p,{children:["Dynamic Few-Shot Classification is an extension of ",(0,t.jsx)(s.a,{href:"/docs/classification/few-show-text-classification",children:"Few-Shot Text Classification"})," that is more suitable for larger datasets. Instead of using a fixed set of examples for each class, it constructs a dynamic subset for each sample on the fly. This allows to efficiently utilize the limited contex window of the model and save the number of consumed tokens."]}),"\n",(0,t.jsx)(s.p,{children:"Let's consider a toy example, where the goal is to determine whether the review is about a book or a movie. The training dataset consists of 6 samples, 3 for each class:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'X = [\n    "I love reading science fiction novels, they transport me to other worlds.", # example 1 - book - sci-fi\n    "A good mystery novel keeps me guessing until the very end.", # example 2 - book - mystery\n    "Historical novels give me a sense of different times and places.", # example 3 - book - historical\n    "I love watching science fiction movies, they transport me to other galaxies.", # example 4 - movie - sci-fi\n    "A good mystery movie keeps me on the edge of my seat.", # example 5 - movie - mystery\n    "Historical movies offer a glimpse into the past.", # example 6 - movie - historical\n]\n\ny = ["books", "books", "books", "movies", "movies", "movies"]\n'})}),"\n",(0,t.jsx)(s.p,{children:"Now let's say we want to classify the following review:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"I have fallen deeply in love with this sci-fi book; its unique blend of science and fiction has me spellbound.\n"})}),"\n",(0,t.jsx)(s.p,{children:"Since the query is about a sci-fi book, we would like to only examples 1 and 4 to be used for classification, since they are the most relevant. If we use the dynamic few-shot classifier with 1 example per class, and investigate which examples were selected, we can see that the model successfully identified examples 1 and 4 as the most relevant ones:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'from skllm.models.gpt.classification.few_shot import DynamicFewShotGPTClassifier\n\nquery = "I have fallen deeply in love with this sci-fi book; its unique blend of science and fiction has me spellbound."\n\nclf = DynamicFewShotGPTClassifier(n_examples=1).fit(X,y)\n\nprompt = clf._get_prompt(query)\nprint(prompt)\n'})}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:'...\n\nSample input:\n"I love reading science fiction novels, they transport me to other worlds."\n\nSample target: books\n\n\nSample input:\n"I love watching science fiction movies, they transport me to other galaxies."\n\nSample target: movies\n\n...\n'})}),"\n",(0,t.jsx)(s.p,{children:"This is achieved by adding a KNN search algorithm as an additional preprocessor. If we assume that the most relevant examples are the closest ones in space, then the problem reduces to a nearest neighbors search and can be tackled in three steps:"}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Vectorization:"}),"\nBefore doing the nearest neighbors search, the training set must be vectorized using an embedding model."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Index construction"})," using an arbitrary nearest neighbors search algorithm. The index allows to efficiently retrieve the nearest neighbors from each class. Currently ",(0,t.jsx)(s.a,{href:"https://scikit-learn.org/stable/modules/neighbors.html",children:"Scikit-Learn KNN"})," and ",(0,t.jsx)(s.a,{href:"https://github.com/spotify/annoy",children:"Annoy"})," are supported, but it is possible to add a custom index as well."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Balanced sampling:"}),"\nThe last thing to be accounted for is a class balancing. If only N nearest neighbors are selected for a few-shot prompting, there is a very high risk that some of the classes will be underrepresented or missing completely. To mitigate this issue, instead of creating a single index, the training data is partitioned by class. In this way, we are able to sample N examples from each class, ensuring the equal representation of each class."]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,t.jsx)(s.p,{children:"The following API reference only lists the parameters needed for the initialization of the estimator. The remaining methods follow the syntax of a scikit-learn classifier."}),"\n",(0,t.jsx)(s.h3,{id:"dynamicfewshotgptclassifier",children:"DynamicFewShotGPTClassifier"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"from skllm.models.gpt.classification.few_shot import DynamicFewShotGPTClassifier\n"})}),"\n",(0,t.jsxs)(s.table,{children:[(0,t.jsx)(s.thead,{children:(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.th,{children:(0,t.jsx)(s.strong,{children:"Parameter"})}),(0,t.jsx)(s.th,{children:(0,t.jsx)(s.strong,{children:"Type"})}),(0,t.jsx)(s.th,{children:(0,t.jsx)(s.strong,{children:"Description"})})]})}),(0,t.jsxs)(s.tbody,{children:[(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"model"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"str"})}),(0,t.jsx)(s.td,{children:'Model to use, by default "gpt-3.5-turbo".'})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"default_label"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"str"})}),(0,t.jsx)(s.td,{children:'Default label for failed prediction; if "Random" -> selects randomly based on class frequencies, by default "Random".'})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"prompt_template"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"Optional[str]"})}),(0,t.jsx)(s.td,{children:"Custom prompt template to use, by default None."})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"key"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"Optional[str]"})}),(0,t.jsx)(s.td,{children:"Estimator-specific API key; if None, retrieved from the global config, by default None."})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"n_examples"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"int"})}),(0,t.jsx)(s.td,{children:"Number of closest examples per class to be retrieved, by default 3."})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"memory_index"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"Optional[IndexConstructor]"})}),(0,t.jsxs)(s.td,{children:["Custom memory index, for details check ",(0,t.jsx)(s.code,{children:"skllm.memory"})," submodule, by default None."]})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"vectorizer"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"Optional[BaseVectorizer]"})}),(0,t.jsxs)(s.td,{children:["Scikit-LLM vectorizer; if None, ",(0,t.jsx)(s.code,{children:"GPTVectorizer"})," is used, by default None."]})]})]})]})]})}function h(e={}){const{wrapper:s}={...(0,n.a)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},1151:(e,s,i)=>{i.d(s,{Z:()=>l,a:()=>a});var t=i(7294);const n={},o=t.createContext(n);function a(e){const s=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:a(e.components),t.createElement(o.Provider,{value:s},e.children)}}}]);